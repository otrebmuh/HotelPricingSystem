# **Appendix A**

The following table presents a comparison between the solution produced by the LLM and the one that is documented in the case study of \[1\].

| Aspect | Case study | LLM generated solution |
| ----- | ----- | ----- |
| **System Structure** | The design splits the system into a Command service (for writes) and Query service (for reads) following Command Query Responsibility Segregation (CQRS), plus an Export service for integration. These services are deployed behind a single API Gateway in a private cloud network. The Command and Query components communicate via an event bus (Kafka) instead of direct calls. This results in only a few core back-end services (command, query, export) that handle all pricing functionality. | The design uses a microservices approach but with more fine-grained separation. In addition to Price Management (command) and Price Query (read) services, there are distinct services for Hotel Management, Rate Management, and Authentication. An API Gateway fronts all these services. An Event Bus enables asynchronous communication between services. The existence of the Query service is essentially an implementation of CQRS. |
| **Components** | Each microservice in the design is structured using standard Spring layered architecture. This mapping of entities to controllers/services ensures all required modules are identified for each use case. The focus is on fundamental components needed for functionality, with security and basic logging considered.  | Each service in the design contains multiple specialized components additional to the standard Spring Layers components (e.g. Calculation Engine, Event Store, Event Publisher with Outbox, Circuit Breaker). This design is more complex and incorporates patterns for reliability and performance. |
| **Sequence diagrams** | The case study presents a limited number of sequence diagrams to illustrate certain functional and non functional scenarios | The architecture document includes sequence diagrams for all functional and quality attribute scenarios. |
| **Contracts** | In iteration 2, a few container and component-level contracts are presented, mostly for illustration purposes.  | The architecture document includes detailed container-level REST contracts for the different services. Endpoints are described in tables with methods, descriptions, request body and response. Additionally, description of events and event payloads is also included. |
| **Communication Style** | The design emphasizes asynchronous communication. The Command service publishes price change events to an event bus, which the Query and Export services subscribe to. External interactions use synchronous REST calls via the API Gateway, but internal services exchange data through events. | The design employs an event-driven architecture for inter-service communication. Services publish events (hotel updates, rate changes, price changes) to a centralized Event Bus and subscribe where needed. The architecture also provides synchronous APIs through the API Gateway for clients. The Query service supports multiple protocols: both REST and gRPC APIs are offered for retrieving prices.  |
| **Domain Modeling** | In iteration 2, an explicit domain model is defined for the Hotel Pricing context. Key domain entities include Hotel, RoomType, Rate, and Price, along with business rules for price calculations. This domain model is confined to the command side (write model). The Query service does not maintain an object model of its own; it simply stores price events in a database for fast retrieval, and the Export service likewise has no domain data (just passes events along). Thus, the case study design treats “hotel pricing” as one domain context, centrally modeled in the command microservice. | The design models similar core concepts (Hotel, Rate, RoomType, Price, BusinessRule, etc.), but splits responsibility across services.This design follows a Domain-Driven Design approach by dividing the domain model across context-specific services. |
| **API Management** | The case study employs an API Gateway as the single entry point for all clients (users or external systems). The Gateway forwards requests to the appropriate back-end microservice. Each microservice exposes RESTful endpoints for its functionality. Authentication and basic authorization are enforced at the gateway and service level (integrating with the cloud identity service). There is no mention of alternate protocols or versioning strategies in the early design; the focus is on providing the necessary REST endpoints for each use case. API security (e.g. token validation) and request validation tactics are considered as part of securing these APIs. | The design also uses a central API Gateway that routes requests to the appropriate service and applies cross-cutting concerns like auth, rate limiting, and input validation. Each microservice defines a set of APIs (documented in the architecture’s Interface section) for its domain. The design explicitly supports API versioning and multiple protocols. In particular, the Price Query service offers both a REST API and a gRPC interface for clients with different needs. |
| **Security** | User login (HPS-1) is handled by leveraging the company’s cloud-based User Identity Service for Single Sign-On. When a user provides credentials, HPS delegates verification to this identity service and, upon success, grants access with appropriate permissions. Each API call must be authenticated (e.g., via tokens issued by that identity service). Authorization checks are mentioned as a requirement, but how this is handled is not discussed. In iteration 1, security tactics such as authenticating and authorizing actors, limiting access to resources, and encrypting API data were identified as critical and were planned from the start. | The design introduces an Authentication Service as a dedicated microservice to handle auth concerns. The API Gateway delegates authentication requests to this Auth service. The Auth service in turn integrates with the same cloud identity provider via OAuth2/OIDC protocols to validate credentials and tokens. It likely manages user sessions or JWT tokens and also stores authorization data. The design explicitly mentions using the cloud identity (CON-2) for user management and SSO, similar to the case study approach, but here it’s encapsulated in a service. |
| **Scalability** | A primary motivation for the case study’s CQRS and microservice design was to address scalability and performance. By splitting the query side from the command side, the system can scale reads independently of writes. In iteration 3, the design explicitly adds replication for the Query service and load balancing to increase throughput for price queries. Kafka as an event store also allows scaling consumers (multiple query or export processors) if needed. This approach ensures that heavy read load from external systems querying prices can be met by adding resources to the Query microservice alone. Other scalability considerations include avoiding shared state (each microservice has its own database) and using stateless services to facilitate horizontal scaling. | The architecture considers independent scaling of each microservice. For instance, if price queries spike, the Price Query Service can be scaled to many instances without touching the others. The inclusion of a distributed caching layer in the Query service supports high read throughput by reducing database load. Additionally, the architecture accounts for scaling in multiple dimensions: it uses CQRS to divide read/write load, and it can leverage multi-region deployment to distribute load and reduce latency for users in those regions. The decision to containerize everything and orchestrate via Kubernetes means the platform can auto-scale services based on demand. |
| **Deployability** | The case study considers deploying all components on a cloud provider. In iteration 1, it was decided to keep all microservices and the event bus within a private network, accessible only through the API Gateway (enhancing security). By iteration 3, more concrete deployment tactics are defined: using a container orchestration service (likely a managed Kubernetes) to run and monitor the microservices, and setting up passive redundancy (a standby deployment in a second availability zone/region) to take over on failures. The event bus (Kafka) is a managed, durable service, removing the need to manage message brokers manually. Each microservice has its own database (e.g., a SQL DB for Command, NoSQL for Query) provided as managed cloud databases. Continuous deployment (CI/CD) is satisfied using a proprietary git-based platform with support for pipelines. | The architecture specifies a robust deployment and DevOps strategy. All services are packaged as containers and deployed on a container orchestration platform (Kubernetes) for consistency across environments. A continuous integration/continuous deployment pipeline builds images, runs tests, and promotes deployments through staging to production. Configuration is managed separately (Infrastructure as Code and a config repository) to enable reproducible, environment-specific deployments. For high availability, the system is deployed in multiple regions with automated failover: if the primary region fails, a secondary region’s services and database replicas take over, using global DNS or load balancer routing. The design also leverages managed cloud services (for databases, identity, etc.) to offload infrastructure management.  |
| **Testability** | The use of the Spring framework and its inversion of control was selected to facilitate unit testing of modules. A concern (CRN-7) was added to ensure all custom business logic components can be unit tested. This implies the design will include a suite of unit tests for services, controllers, etc., and likely some integration tests for the event flow. However, the case study description does not describe a full testing environment setup. No specific mention is made of test automation tools or frameworks beyond standard unit testing. | The design dedicates an entire infrastructure for testing. It uses containerized test environments via TestContainers to spin up ephemeral databases, Kafka brokers, and other dependencies for integration tests. There is a suite for contract testing to ensure that each service’s APIs meet the expectations of its consumers (using consumer-driven contracts and schema validation). Mock versions of external systems are provided to test interactions without relying on live systems. The test infrastructure supports automated provisioning of these components to run integration tests in CI pipelines. Additionally, test data management tools reset and seed databases between tests to ensure isolation. All of this is integrated into the CI/CD pipeline, so tests run on each build and deployment, with reporting and failure alerts. |

***Table A**. Design comparison between published case study and LLM solution*
